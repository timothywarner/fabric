{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99d39178-c55b-4fc0-8390-b89dc1e16203",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Lab 6: LLM Programming and Azure AI Services in Fabric\n",
    "\n",
    "Azure AI services, help developers and organizations rapidly create intelligent, cutting-edge, market-ready, and responsible applications with prebuilt and customizable APIs and models. \n",
    "\n",
    "### Exercise overview\n",
    "\n",
    "In this exercise, you'll learn how to use Azure AI services native endpoints in Fabric to enrich your data with prebuilt AI models without any prerequisite. The scenario is to use SynapseML integration with Azure AI Services to leverage Azure AI Translator and Text Analytics services to perform different tasks such as language translation and sentiment analysis on customer reviews and feedback. Moreover, you will learn how to use SynapseML and its integration with LangChain to build an LLM model that categorizes customer reviews and feedback into major themes that influenced customers' decision to leave the bank. Finally, you will learn how to use OpenAI Chat Completion API to perform Q&A on your DataFrame.\n",
    "\n",
    "The main steps in this notebook are:\n",
    "\n",
    "1. Import and Install reuired libraries\n",
    "2. Load the data and perform exploratory data analysis\n",
    "3. Use prebuilt Azure AI models in Fabric for translation and sentiment analysis\n",
    "4. Leverage SynapseML and LangChain to create an LLM model to categorize customer feedback\n",
    "5. Use SynapseML and OpenAI Chat Completion to perform Q&A on the DataFrame\n",
    "\n",
    "### Helpful links\n",
    "- [SynapseML in Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/data-science/ai-services/ai-services-overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075074ba-2418-4e78-a358-61eda2365a4a",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 1: Setup your notebook\n",
    "\n",
    "### Select Lakehouse\n",
    "\n",
    "First, add the Lakehouse you created from the prior lab exercise.\n",
    "\n",
    "<br>\n",
    "\n",
    "![image-alt-text](https://synapseaisolutionsa.blob.core.windows.net/public/Fabric-Conference/add-lakehouse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8788209-1bb6-48cc-9b85-09e50d3732ca",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 2: Install and import required libraries\n",
    "\n",
    "Before we move forward with sentiment analysis of customer reviews, it is imperative to first install and import the essential libraries from Spark and SynapseML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde8053-f1f8-492c-b0d9-47e8006b6acd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai==0.28.1 | grep -v 'already satisfied'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9879c0-b9d0-4585-8961-0270a90e8225",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai langchain==0.0.331 | grep -v 'already satisfied'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d17c9d-2ea4-45aa-88ab-eac737e06bcf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install wordcloud textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01be776e-db53-4c3d-859e-c7de136ba5b7",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "> [!IMPORTANT]\n",
    "> **Run the following cell in order to install the required packages for Copilot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ab8b2-0052-4781-a45e-cc14280ff529",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install https://aka.ms/chat_magics-0.0.0-py3-none-any.whl\n",
    "%load_ext chat_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fd549-f48d-4d7e-b632-d42bb0d85723",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os, openai, requests, langchain, uuid\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import TransformChain, LLMChain, SimpleSequentialChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "import synapse.ml.core\n",
    "from synapse.ml.services.language import AnalyzeText\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "os.environ['OPENAI_API_VERSION'] = '2023-05-15'\n",
    "from pyspark.sql.functions import explode, split, col\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e444fde-8de6-4811-bc02-5caff1085863",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 3: Load and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5e739-bbbf-4548-b2f4-aa11e3e97f2e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "IS_CUSTOM_DATA = False  # if TRUE, dataset has to be uploaded manually\n",
    "\n",
    "DATA_FOLDER = \"Files/customer_feedback\"  # folder with data files\n",
    "DATA_FILE = \"customer_feedback.csv\"  # data file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ace67e-35ad-49f9-9a12-1c1382745e18",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if not IS_CUSTOM_DATA:\n",
    "\n",
    "    import os, requests\n",
    "    # Download demo data files into lakehouse if not exist\n",
    "    remote_url = \"https://synapseaisolutionsa.blob.core.windows.net/public/LLM-Demo\"\n",
    "    fname = \"customer_feedback.csv\"\n",
    "    download_path = f\"/lakehouse/default/{DATA_FOLDER}/raw\"\n",
    "\n",
    "    if not os.path.exists(\"/lakehouse/default\"):\n",
    "        raise FileNotFoundError(\"Default lakehouse not found, please add a lakehouse and restart the session.\")\n",
    "    os.makedirs(download_path, exist_ok=True)\n",
    "    if not os.path.exists(f\"{download_path}/{fname}\"):\n",
    "        r = requests.get(f\"{remote_url}/{fname}\", timeout=30)\n",
    "        with open(f\"{download_path}/{fname}\", \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "    print(\"Downloaded demo data files into lakehouse.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172a005-1b5d-4549-b8a5-1b40afb33672",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_spark = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", True)\n",
    "    .load(f\"{DATA_FOLDER}/raw/{DATA_FILE}\")\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea7f3a4-5543-4aaf-9ae7-1717f7b37a7e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "display(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290307d-0daa-401d-be48-3af3af16d507",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# List the columns of Spark DataFrame\n",
    "df_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1a2f8-98a9-4bff-ad57-8bd04e0e6a33",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Display DataFrame schema\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be4c46c-b29c-435d-bc9b-1f0519373a11",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Word Cloud of most common words\n",
    "\n",
    "The word cloud of most common words is a visualization technique illustrating the prevalent terms within a text dataset. Initially, the text undergoes preprocessing to remove irrelevant elements such as punctuation and stopwords.\n",
    "Following this, the frequency of each word is calculated based on its occurrence in the dataset. These words are then visually represented in a cloud-like formation, where larger words indicate higher frequency.\n",
    "This visualization offers a swift and intuitive insight into the primary themes or topics present in the text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2aab17-818c-4b43-8a8b-91baca618b24",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split, col\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "reviews_text = \" \".join(review['CustomerFeedback'] for review in df_spark.select('CustomerFeedback').collect())\n",
    "\n",
    "# Convert the reviews text to lowercase\n",
    "reviews_text_lower = reviews_text.lower()\n",
    "# Create a list of words\n",
    "words = reviews_text_lower.split()\n",
    "# Load English stopwords\n",
    "stopwords = set(StopWordsRemover().getStopWords())\n",
    "# Remove stopwords from the list of words\n",
    "filtered_words = [word for word in words if word not in stopwords]\n",
    "# Join the filtered words back into a single string\n",
    "filtered_reviews_text = \" \".join(filtered_words)\n",
    "# Generate WordCloud with stopwords removed\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(filtered_reviews_text)\n",
    "\n",
    "# Plot WordCloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Customer Reviews')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971b73d-8b49-4da3-94cf-d0e11d14fd53",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Sentiment analysis pie chart \n",
    "A Sentiment Analysis Pie Chart is a visual representation of sentiment categories (such as positive, negative, and neutral) derived from analyzing text data. It displays the distribution of sentiments within the dataset, typically using a circular chart where each segment represents a sentiment category and its size reflects the proportion of text data assigned to that sentiment category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05f21c-feff-437b-8109-d643d7ac7d01",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Define a UDF for sentiment analysis using TextBlob\n",
    "def get_sentiment(text):\n",
    "    polarity = TextBlob(text).sentiment.polarity\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Register UDF\n",
    "sentiment_udf = udf(get_sentiment, StringType())\n",
    "\n",
    "# Apply sentiment analysis to each review\n",
    "df_with_sentiment = df_spark.withColumn('sentiment', sentiment_udf('CustomerFeedback'))\n",
    "\n",
    "# Calculate count of each sentiment category\n",
    "sentiment_counts = df_with_sentiment.groupBy('sentiment').count()\n",
    "\n",
    "# Convert to Pandas DataFrame for plotting\n",
    "sentiment_counts_pd = sentiment_counts.toPandas()\n",
    "\n",
    "# Plotting\n",
    "sentiment_counts_pd.plot(kind='pie', y='count', labels=sentiment_counts_pd['sentiment'],\n",
    "                         autopct='%1.1f%%', startangle=90, figsize=(8, 8))\n",
    "plt.ylabel('')\n",
    "plt.title('Distribution of Sentiments in Reviews')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73b402f-a14a-4ee0-b676-05c0e0965422",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 4: Utilize Azure AI Services in Fabric\n",
    "\n",
    "Leverage Azure AI services for various tasks including:\n",
    "\n",
    "- Translate the customer comments and feedback to another language of your choice such as French and German.\n",
    "- Perform sentiment analysis on customer comments and feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1f8ef-44b1-4248-8adc-133d46be3afb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Translate to German and French and Spanish\n",
    "from synapse.ml.services.translate import Translate\n",
    "from pyspark.sql.functions import col, flatten\n",
    "\n",
    "translate = (Translate()\n",
    "    .setTextCol(\"CustomerFeedback\")\n",
    "    .setToLanguage([\"de\", \"fr\", \"es\"])\n",
    "    .setOutputCol(\"translation\")\n",
    "    .setConcurrency(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2a18c-14cf-4118-a9f2-a0477809ab8b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Perform sentiment analysis\n",
    "from synapse.ml.services.language import AnalyzeText\n",
    "\n",
    "sentiment_analysis_model = (\n",
    "    AnalyzeText()\n",
    "    .setKind(\"SentimentAnalysis\")\n",
    "    .setTextCol(\"CustomerFeedback\")\n",
    "    .setOutputCol(\"sentiment_analysis\")\n",
    "    .setErrorCol(\"error\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a28d2d-92a1-47dc-8c89-e5a58e14f5ab",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Demonstrate the model performance\n",
    "\n",
    "Create a small sample of the spark DataFrame to validate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ae2d7-2ce7-43a8-80c7-a14dbbbfddc0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "df_sample = df_spark.sample(False, 0.2, seed=0).limit(30)\n",
    "display(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810e40f-342a-4bef-ab10-3258e6ce39f6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Perform translation and flatten the translation results\n",
    "df_translation_result = translate.transform(df_sample)\\\n",
    "    .withColumn(\"translation\", explode(col(\"translation.translations\")))\n",
    "# Extract translated text into separate columns for German, French, and Spanish\n",
    "df_translation_result = df_translation_result\\\n",
    "    .withColumn(\"CustomerFeedback_German\", col(\"translation.text\").getItem(0))\\\n",
    "    .withColumn(\"CustomerFeedback_French\", col(\"translation.text\").getItem(1))\\\n",
    "    .withColumn(\"CustomerFeedback_Spanish\", col(\"translation.text\").getItem(2))\\\n",
    "    .select(\"CustomerFeedback\", \"CustomerFeedback_German\", \"CustomerFeedback_French\", \"CustomerFeedback_Spanish\")\n",
    "# Display the original feedback and translations\n",
    "display(df_translation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e01647-415f-4c6c-8c2b-751ae6434400",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Perform sentiment analysis\n",
    "df_sentiment_results = sentiment_analysis_model.transform(df_sample)\n",
    "# Display the original feedback and the sentiment analysis\n",
    "display(df_sentiment_results.select(\"CustomerFeedback\", \"sentiment_analysis.documents.sentiment\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9be84c-f76d-496b-82e1-9ce6e2a48715",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 6: Create the LLM model\n",
    "\n",
    "Leverage SynapseML and LangChain to initialize a conversational agent that utilizes the specified OpenAI GPT-3.5 model hosted on Azure to categorize customer feedbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607c1d4-1769-414c-b2eb-59c94e778445",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame that shows the customers who have left the bank\n",
    "df_exited = df_spark.filter(df_spark['Exited'] == 1)\n",
    "display(df_exited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e7023-d3c3-4385-be50-6bf75d806678",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "df_sample_exited = df_exited.sample(False, 0.2, seed=0).limit(30)\n",
    "display(df_sample_exited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c4f21-b430-4704-b412-b2a59a82acce",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    model_name='gpt-35-turbo',\n",
    "    temperature=0.1,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    Your job is to summarize reasons by simple phrases why customer closes the bank account.\n",
    "    Please use all information available in the dataset to determine only two reasons as if this is going to mentioned to the bank manager.\n",
    "    Provide multiple reasons separated by a comma if multiple reasons are approprate.\n",
    "    If you are unsure or a reason cannot be determined, say \"Unknown\".\n",
    "    Write the reason as a single word or short phrase.\n",
    "    Examples:\n",
    "    I recently closed my bank account due to the lack of transparency and uncompetitive interest rates: High interest rates,\n",
    "    After dealing with increasing fees, hidden charges, and lack of transparency, I made the decision to close my bank account: Hidden bank charges, increasing bank fees \"\"\"\n",
    "\n",
    "system_message = SystemMessage(content=template)\n",
    "human_template= \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message_prompt])\n",
    "chain = LLMChain(llm=llm, prompt=chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136017cc-e77b-4462-a854-87e850b7bc0b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "from synapse.ml.services.langchain import LangchainTransformer\n",
    "\n",
    "transformer = (\n",
    "    LangchainTransformer()\n",
    "    .setInputCol(\"CustomerFeedback\")\n",
    "    .setOutputCol(\"Customer_Reason\")\n",
    "    .setChain(chain)\n",
    ")\n",
    "display(transformer.transform(df_sample_exited))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14793f17-e647-4ddf-9c0a-2bc64a27214b",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Step 7: Perform Q&A on the DataFrame\n",
    "\n",
    "Leverage SynapseML integration with OpenAI Chat Completion API to perform simple Q&A on the data using the specified OpenAI GPT-3.5 model hosted on Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be2889-78de-4bab-b280-5b2a57566790",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "You will define a function that takes a DataFrame, a prompt template with placeholders, and the name for the new column that will be added as the prompt column to the DataFrame. The goal is to replace the placeholders in the template with column values from the DataFrame and adds a new column with resulting values to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8aa0fd-cdbd-457b-a5c8-d85aa3e2c729",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "import re\n",
    "\n",
    "def generate_prompt_column(df, prompt, new_col):\n",
    "    # Use regular expression to extract all the placeholders in the prompt string\n",
    "    placeholders = re.findall(r'\\{(.*?)\\}', prompt)\n",
    "    # Initialize the format expression with the template where placeholders are replaced by \"%s\"\n",
    "    format_expr = prompt\n",
    "    # A loop iterating over each placeholder in the prompt string\n",
    "    for placeholder in placeholders:\n",
    "        # Construct the dynamic expression to replace placeholders with column values\n",
    "        format_expr = format_expr.replace(f\"{{{placeholder}}}\", \"%s\")\n",
    "    # Construct comma-separated string of column names corresponding to the placeholders in the prompt string\n",
    "    format_args = \", \".join([f\"`{col}`\" for col in placeholders])\n",
    "    # Construct the final expression for Spark SQL by replacing using the column values provided in format_args\n",
    "    expr_string = f\"format_string('{format_expr}', {format_args})\"\n",
    "    # Create a new column\n",
    "    df = df.withColumn(new_col, F.expr(expr_string))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e931765-34b0-4010-8145-ccd31acc73b4",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "You will define another function that leverages SynapseML integration with OpenAI chat completion API to perform chat completion based on input questions. It then stores the results in a new column of the DataFrame. Note that the `generate_prompt_column` function defined above provides the necessary prompts for interacting with OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbe9c31-2ff6-42bb-b945-5f27917018d8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from synapse.ml.services.openai import OpenAIChatCompletion\n",
    "\n",
    "def generate_chat_response(df, question, new_col, show_errors=False):\n",
    "    # Instantiate OpenAIChatCompletion object and configure settings\n",
    "    chat_completion = (\n",
    "        OpenAIChatCompletion()\n",
    "        .setDeploymentName(\"gpt-35-turbo\")\n",
    "        .setMessagesCol(\"messages\")\n",
    "        .setErrorCol(\"errors\")\n",
    "        .setOutputCol(\"chat_completions\")\n",
    "    )\n",
    "    # Generate prompts for the OpenAI model based on the input DataFrame and the question\n",
    "    # The generate_prompt_column function defined above is used to create a new column named \"prompt\" in the DataFrame df \n",
    "    prompt_df = generate_prompt_column(df, question, \"prompt\") \\\n",
    "        .withColumn(\n",
    "            \"messages\",\n",
    "            F.array(F.struct(\n",
    "                F.lit(\"user\").alias(\"role\"),\n",
    "                F.col(\"prompt\").alias(\"content\"),\n",
    "                F.lit(\"user\").alias(\"name\"),\n",
    "            ))\n",
    "        )\n",
    "    # Perform chat completion using the OpenAI specified model and extract the completion result and assign it to the new column\n",
    "    # Drop unnecessary columns such as \"prompt\", \"chat_completions\", and \"messages\" from the DataFrame\n",
    "    results = (chat_completion\n",
    "        .transform(prompt_df)\n",
    "        .withColumn(new_col, F.col(\"chat_completions.choices\").getItem(0).getItem(\"message\").getItem(\"content\"))\n",
    "        .drop(\"prompt\", \"chat_completions\", \"messages\"))\n",
    "    if show_errors:\n",
    "        return results\n",
    "    else:\n",
    "        return results.drop(\"errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b372085b-2976-4cb1-9cae-c09ff5dfc278",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Determine whether a customer feedback is positive or negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e2daa4-874f-4045-9cf1-00dddfbb8292",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_sample_gpt= generate_chat_response(df_sample, \"Is this a positive customer feedback: {CustomerFeedback}? Answer just \\\"true\\\" or \\\"false\\\"\", \"PositiveCustomerFeedback\")\n",
    "display(df_sample_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa6342-e596-47ef-87c0-67d6ad034f32",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "You can see that a new column titled `PositiveCustomerFeedback` is added to DataFrame that contains information about whether the customer feedback is positive or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c6997e-ed3c-4bd4-829f-13e14b5e2617",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Determine whether a customer credit score is good or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2cdde-fb3b-4071-88b7-f5c6b19b522a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_sample_gpt= generate_chat_response(df_sample, \"Is this a good credit score: {CreditScore}? Answer just \\\"true\\\" or \\\"false\\\"\", \"GoodCreditScore\")\n",
    "display(df_sample_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba7edb-f621-45d4-bdc2-a21472c44933",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "You can see that a new column titled `GoodCreditScore` is added to DataFrame that contains information about whether the customer has a good credit score or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9427e1-8aa4-4ce9-a82f-fa9e7e33e0c3",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Excercise\n",
    "\n",
    "You want to understand the average sentiment for different geographies. \n",
    "\n",
    "Use the tools you have learned about, e.g., copilot, data wrangler, LLM programming, etc. to help answer this question."
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
