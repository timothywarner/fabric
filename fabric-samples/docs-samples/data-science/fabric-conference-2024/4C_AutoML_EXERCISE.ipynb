{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6f044c-53cb-450f-946e-f644bf94b982",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# AutoML in Fabric Data Science\n",
    "\n",
    "AutoML (Automated Machine Learning) is a collection of methods and tools that automate machine learning model training and optimization with little human involvement. The aim of AutoML is to simplify and speed up the process of choosing the best machine learning model and hyperparameters for a given dataset, which usually demands a lot of skill and computing power.\n",
    "\n",
    "AutoML can help ML professionals and developers from different sectors to:\n",
    "\n",
    "1. Build ML solutions with minimal coding\n",
    "1. Reduce time and cost\n",
    "1. Apply data science best practices\n",
    "1. Solve problems quickly and efficiently\n",
    "\n",
    "![image-alt-text](https://synapseaisolutionsa.blob.core.windows.net/public/Fabric-Conference/flaml-automl-workflow.png)\n",
    "\n",
    "### Exercise overview\n",
    "In this exercise, we will use `churn_data_clean` and ```flaml.AutoML``` to automate their machine learning tasks. We will track the results of these iterations with MLFlow.\n",
    "\n",
    "### Helpful links\n",
    "- [Autologging in Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/data-science/mlflow-autologging)\n",
    "- [Fabric Experiments](https://learn.microsoft.com/en-us/fabric/data-science/machine-learning-experiment)\n",
    "- [AutoML Examples](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eabe17b-5ccd-406d-b17e-592656d1c491",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Install Fabric integrated version of FLAML\n",
    "%pip install https://synapsemldatascience.blob.core.windows.net/releases/flaml/FLAML-2.1.1.post4-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d8ef67-2acf-4a43-be27-d77a6752255b",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84dd65-1044-4401-9611-be9a7fc8e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = spark.read.format(\"delta\").load(\"Tables/churn_data_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56786e01-a93b-4561-959f-ce97c11b6ad3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "display(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c7bad-b7f2-4943-a824-b6ad3a4d4257",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Set up MLflow experiment tracking\n",
    "\n",
    "MLflow is an open source platform that is deeply integrated into the Data Science experience in Fabric and allows to easily track and compare the performance of different models and experiments without the need for manual tracking. For more information, see [Autologging in Microsoft Fabric](https://aka.ms/fabric-autologging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5330a-88a0-4b4d-af25-fda2d8642d67",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Disable exclusive mode for autologging to track additional metrics\n",
    "mlflow.autolog(exclusive=False)\n",
    "\n",
    "# Set the MLflow experiment to \"FabCon-Demo\" and enable automatic logging\n",
    "mlflow.set_experiment(\"FabCon-Demo-Experiment\")\n",
    "\n",
    "# Set random state for all the iterations\n",
    "random_state = 41\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9fa7f4-9278-47bb-85aa-346987d435ab",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Set the logging level\n",
    "\n",
    "You can configure the logging level to suppress unnecessary outputs from the SynapseML library to keep the logs cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da4fa20-9722-4ff1-921c-b4aa2715397e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    " \n",
    "logging.getLogger('synapse.ml').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('mlflow.utils').setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15072f3a-2f22-47c8-b0e0-7dc3032afde6",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 2: Train a baseline machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb75d1f-abc1-40d3-a78e-9ecbad3924e4",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "With your data in place, you can now define the model. You'll train a LightGBM model in this notebook. You will also use MLfLow and Fabric Autologging to track the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3917445-1682-4858-b381-7fbbc707b499",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Generate train-test datasets\n",
    "\n",
    "Split the data into training and test datasets with an 80/20 ratio and prepare the data to train your machine learning model. Since we are working with LightGBM, we'll convert our dataset to Pandas for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f83b2-b549-44b5-905c-e1cf89654fcd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Convert Spark DataFrame to Pandas DataFrame\n",
    "df_final_pd = df_final.toPandas()\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "y = df_final_pd[\"Exited\"]\n",
    "X = df_final_pd.drop(\"Exited\", axis=1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d994d9f6-48af-40ca-8f7c-3f60ed3a3770",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Train and evaluate the baseline model\n",
    "\n",
    "Train a `LightGBMClassifier` model on the training data that is configured with appropriate settings for binary classification and imbalance handling. Then make predictions on the test data using this trained model. Predicted probabilities for the positive class and true labels from the test data are extracted, followed by calculation of the ROC-AUC score using sklearn's `roc_auc_score` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f358ad9-df15-4707-98ec-b229eb9a11af",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import mlflow\n",
    "import logging\n",
    "\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"default\") as run:\n",
    "    # Define LGBMClassifier with specified parameters\n",
    "    lgbm_model = LGBMClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=2,\n",
    "        max_depth=2,\n",
    "        num_leaves=3,\n",
    "        objective='binary',\n",
    "        random_state=random_state,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    # Capture run_id for model prediction later\n",
    "    lgbm_model_run_id = run.info.run_id \n",
    "\n",
    "    # Fit the model to the training data\n",
    "    lgbm_model.fit(X_train, y_train) \n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = lgbm_model.predict(X_test)\n",
    "\n",
    "    # Compute ROC AUC score\n",
    "    roc_auc_lgbm = roc_auc_score(y_train, lgbm_model.predict_proba(X_train)[:, 1])\n",
    "\n",
    "    # Log ROC AUC score\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de922a-e0d1-44d1-9549-0ebcb7beb33c",
   "metadata": {},
   "source": [
    "## Step 3: Create an AutoML trial with FLAML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424426de-91cb-42e0-b74a-7ab5f5530e31",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In this section, you'll create an AutoML trial using the FLAML package, configure the trial settings, convert the Spark dataset to a Pandas on Spark dataset, run the AutoML trial, and view the resulting metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494221b-38ef-43bd-aad4-e1e1d51b1d3b",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Generate train-test datasets with Spark\n",
    "\n",
    "Split the data into training and test datasets with an 80/20 ratio and prepare the data to train your machine learning model. This preparation involves importing the `VectorAssembler` from PySpark ML to combine feature columns into a single `features` column. Then, you'll use the `VectorAssembler` to transform the training and test datasets, resulting in `train_data` and `test_data` DataFrames containing the target variable `Exited` and the feature vectors. These datasets are now ready for building and evaluating machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3d8f3-1173-46cb-8bb0-16c355797369",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import the necessary library for feature vectorization\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Train-Test Separation\n",
    "train_raw, test_raw = df_final.randomSplit([0.8, 0.2], seed=41)\n",
    "\n",
    "# Define the feature columns (excluding the target variable 'Exited')\n",
    "feature_cols = [col for col in df_final.columns if col != \"Exited\"]\n",
    "\n",
    "# Create a VectorAssembler to combine feature columns into a single 'features' column\n",
    "featurizer = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Transform the training and testing datasets using the VectorAssembler\n",
    "train_data = featurizer.transform(train_raw)[\"Exited\", \"features\"]\n",
    "test_data = featurizer.transform(test_raw)[\"Exited\", \"features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea175a0-b673-49e2-8db3-35879b133673",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Configure the AutoML trial and settings\n",
    "\n",
    "Import the required classes and modules from the FLAML package and instantiate AutoML, which automates the machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7bdd8-20c1-4867-8ada-1aa109a88d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the AutoML class from the FLAML package\n",
    "from flaml import AutoML\n",
    "from flaml.automl.spark.utils import to_pandas_on_spark\n",
    "\n",
    "# Create an AutoML instance\n",
    "automl_spark = AutoML()\n",
    "\n",
    "# Define AutoML settings\n",
    "settings = {\n",
    "    \"time_budget\": 100,        # Total running time in seconds\n",
    "    \"metric\": 'roc_auc',       # Optimization metric (ROC AUC in this case)\n",
    "    \"task\": 'classification',  # Task type (classification)\n",
    "    \"log_file_name\": 'flaml_experiment.log',  # FLAML log file\n",
    "    \"max_iter\":10, \n",
    "    \"seed\": 41,                # Random seed\n",
    "    \"mlflow_exp_name\": \"FabCon-Demo-Experiment\",      # MLflow experiment name\n",
    "    \"verbose\":1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee82437-1dac-4ea6-a471-1878a62d4040",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Convert to Pandas on Spark\n",
    "\n",
    "To execute AutoML with a Spark-based dataset, you must convert it to a Pandas on Spark dataset using the `to_pandas_on_spark` function. This ensures FLAML can efficiently work with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c86a7-8e85-4a22-94b4-0e1220c22b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_automl = to_pandas_on_spark(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38628ca7-98ac-4912-9ed1-a7786997fc54",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Run the AutoML trial\n",
    "\n",
    "Execute the AutoML trial, using a nested MLflow run to track the experiment within the existing MLflow run context. The trial is conducted on the Pandas on Spark dataset `df_automl` with the target variable `Exited`, and the defined settings are passed to the `fit` function for configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f9ac3-b06d-4ef8-b797-c8813f404177",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The main flaml automl API'''\n",
    "\n",
    "with mlflow.start_run(nested=True, run_name = \"spark_automl\"):\n",
    "    automl_spark.fit(dataframe=df_automl, label='Exited', isUnbalance=True, **settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d677d8-fd63-4285-bf71-5fa57fab4378",
   "metadata": {},
   "source": [
    "#### View resulting metrics\n",
    "\n",
    "Retrieve and display the results of the AutoML trial. These metrics offer insights into the performance and configuration of the AutoML model on the provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b462d99-d101-429e-a6dc-3cb415d76c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and display the best hyperparameter configuration and metrics\n",
    "print('Best hyperparameter config:', automl_spark.best_config)\n",
    "print('Best ROC AUC on validation data: {0:.4g}'.format(1 - automl_spark.best_loss))\n",
    "print('Training duration of the best run: {0:.4g} s'.format(automl_spark.best_config_train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d3b5c3-069e-460b-a9bd-c8bedc6d135f",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 4: Parallelize your AutoML trial with Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c8db21-64d5-4b6d-b085-d5266e18ba0e",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In scenarios where your dataset can fit into a single node and you aim to harness Spark's capabilities for running multiple parallel AutoML trials simultaneously, you can follow these steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf92a21-cf98-4660-bfcf-c2557de722aa",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Configure parallelization settings\n",
    "\n",
    "Configure `use_spark` to `True` to enable Spark-based parallelism. By default, FLAML will initiate one trial per executor. You can customize the number of concurrent trials using the `n_concurrent_trials` argument. To learn more about how to parallelize your AutoML trails, you can visit [FLAML documentation for parallel Spark jobs](https://microsoft.github.io/FLAML/docs/Examples/Integrate%20-%20Spark#parallel-spark-jobs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c40983-c772-4bd3-860f-0f36f4b00760",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Convert to Pandas for parallelization\n",
    "pandas_df = train_raw.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22185f50-8fe0-4b00-bd8a-79e0ecbdf186",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create an AutoML instance\n",
    "automl = AutoML()\n",
    "\n",
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(\"FabCon-Demo-Experiment\")\n",
    "\n",
    "# Define settings\n",
    "settings = {\n",
    "    \"time_budget\": 50,           # Total running time in seconds\n",
    "    \"metric\": 'roc_auc',         # Optimization metric (ROC AUC in this case)\n",
    "    \"task\": 'classification',    # Task type (classification)\n",
    "    \"seed\": 41,                  # Random seed\n",
    "    \"use_spark\": True,           # Enable Spark-based parallelism\n",
    "    \"n_concurrent_trials\": 3,    # Number of concurrent trials to run\n",
    "    \"force_cancel\": True,        # Force stop training once time_budget is used up\n",
    "    \"mlflow_exp_name\": \"FabCon-Demo\",  # MLflow experiment name\n",
    "    \"verbose\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd6b95-0fdc-4541-9e9c-101cfb9cb96d",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Run the AutoML trial\n",
    "\n",
    "Execute the AutoML trial in parallel with the specified settings. Note that a nested MLflow run will be utilized to track the experiment within the existing MLflow run context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61342c1-289c-47ea-83dd-a308a4a3d898",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "'''The main flaml automl API'''\n",
    "with mlflow.start_run(nested=True, run_name = \"parallel_automl\"):\n",
    "    automl.fit(dataframe=pandas_df, label='Exited', **settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a147c-29b4-48bd-9f84-1638341259df",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Understand AutoML runs\n",
    "\n",
    "The `flaml.visualization` module provides functions for plotting and comparing runs in FLAML. Users can utilize Plotly to interact with their AutoML experiment plots. A **feature importance plot** is a valuable visualization tool enabling you to grasp the significance of various input features in determining the predictions of the final, best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87cb96-83d2-4634-8b39-6a3d0599757a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import flaml.visualization as fviz\n",
    "fig = fviz.plot_feature_importance(automl)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d02f59-9564-4069-8ab0-9b2d64193cb0",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### View metrics\n",
    "\n",
    "Upon completion of the parallel AutoML trial, retrieve and showcase the results, including the best hyperparameter configuration, ROC-AUC on the validation dataset, and the training duration of the top-performing run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5de0c-8a29-47ce-8266-14df924d867d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "''' retrieve best config'''\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best roc_auc on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35808b2-1282-44e6-9835-b39daf9c3dd7",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2da0ce8c-fa46-4189-8a8a-fd33a921e958",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Experiments artifact for tracking model performance\n",
    "\n",
    "The experiment runs are automatically saved in the experiment artifact that can be found from the workspace. They're named based on the name used for setting the experiment. All of the trained models, their runs, performance metrics and model parameters are logged as can be seen from the experiment page shown in the image below.   \n",
    "\n",
    "To view your experiments:\n",
    "1. On the left panel, select your workspace.\n",
    "1. Find and select the experiment name, in this case _sample-automl-experiment_.\n",
    "\n",
    "<img src=\"https://synapseaisolutionsa.blob.core.windows.net/public/AutoML_nested_details.png\"  width=\"400%\" height=\"100%\" title=\"Screenshot shows logged values for one of the models.\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a58b462-5281-45af-8a1e-f721f6c048f8",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Step 5: Save as the final machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c2668a-e8cd-4db4-bebe-d9301af26fb9",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Upon completing the AutoML trial, you can now save the final, tuned model as an ML model in Fabric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c19351e-5282-469b-b896-5679eea7593f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Specify the model name and the path where you want to save it in the registry\n",
    "model_name = \"fabcon-churn-model\"  # Replace with your desired model name\n",
    "model_path = f\"runs:/{automl.best_run_id}\"\n",
    "\n",
    "# Register the model to the MLflow registry\n",
    "registered_model = mlflow.register_model(model_uri=model_path, name=model_name)\n",
    "\n",
    "# Print the registered model's name and version\n",
    "print(f\"Model '{registered_model.name}' version {registered_model.version} registered successfully.\")"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {},
   "lakehouse": {}
  },
  "description": null,
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "notebook_environment": {},
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "save_output": true,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {},
    "enableDebugMode": false
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
