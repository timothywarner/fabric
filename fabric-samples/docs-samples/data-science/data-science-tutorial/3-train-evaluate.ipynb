{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7cbbac5",
   "metadata": {},
   "source": [
    "# Part 3: Train and register a machine learning model\n",
    "\n",
    "In this tutorial, you'll learn to train multiple machine learning models to select the best one in order to predict which bank customers are likely to leave.\n",
    "\n",
    "Once a model is trained, you'll register the trained model, and log the used hyperaparameters as well as the evaluation metrics using Microsoft Fabric's native integration with the MLflow framework.\n",
    "\n",
    "[MLflow](https://mlflow.org/docs/latest/index.html) is an open source platform for managing the machine learning lifecycle with features like Tracking, Models, and Model Registry. MLflow is natively integrated with the Fabric Data Science experience.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Complete [Part 2: Explore and clean data](https://learn.microsoft.com/fabric/data-science/tutorial-data-science-explore-notebook).\n",
    "- Attach the same lakehouse you used in Part 2 to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef269b0-0adc-428d-b2f0-7acbb3170142",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Install custom libraries\n",
    "\n",
    "For this notebook, you'll install imbalanced-learn (imported as `imblearn`) using `%pip install`. Imbalanced-learn is a library for Synthetic Minority Oversampling Technique (SMOTE) which is used when dealing with imbalanced datasets. The PySpark kernel will be restarted after `%pip install`, so you'll need to install the library before you run any other cells. \n",
    "\n",
    "You'll access SMOTE using the `imblearn` library. Install it now using the in-line installation capabilities (e.g., `%pip`, `%conda`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b972e90-29c3-4b75-8837-2d3830dd2a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install imblearn for SMOTE using pip\n",
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f696837",
   "metadata": {},
   "source": [
    "> [!TIP]\n",
    ">\n",
    "> When you install a library in a notebook, it is only available for the duration of the notebook session and not in the workspace. If you restart the notebook, you'll need to install the library again. If you have a library you often use, you could instead [install it in your workspace](https://learn.microsoft.com/fabric/data-science/python-guide/python-library-management) to make it available to all notebooks in your workspace without further installs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d1fffa-b0fb-4ac8-9d7f-41339ca50faf",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "\n",
    "## Load the data\n",
    "\n",
    "Load the delta table from the lakehouse in order to read the cleaned data you created in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e525b-b00c-4537-9edb-cc445782d736",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "SEED = 12345\n",
    "df_clean = spark.read.format(\"delta\").load(\"Tables/df_clean\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9eead-c909-4cb2-848f-12d2ad6a3df3",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Generate experiment for tracking and logging the model using MLflow\n",
    "\n",
    "This section demonstrates how to generate an experiment, specify model and training parameters as well as scoring metrics, train the models, log them, and save the trained models for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33810bac-86b5-46a6-9c37-cd28ca679a43",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# Setup experiment name\n",
    "EXPERIMENT_NAME = \"bank-churn-experiment\"  # MLflow experiment name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b415622-97f7-480f-bc72-9f63053742fc",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Extending the MLflow autologging capabilities, autologging works by automatically capturing the values of input parameters and output metrics of a machine learning model as it is being trained. This information is then logged to your workspace, where it can be accessed and visualized using the MLflow APIs or the corresponding experiment in your workspace. \n",
    "\n",
    "All the experiments with their respective names are logged and you'll be able to track their parameters and performance metrics. To learn more about  autologging, see  [Autologging in Microsoft Fabric](https://aka.ms/fabric-autologging)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8693b-2970-4daf-ad31-067a25b80b60",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Set experiment and autologging specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08b40bc-e4c1-4faf-a388-2ed301580d16",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "mlflow.autolog(exclusive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634163fa-5062-469e-a5e9-ed49ef7e4607",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Import scikit-learn and LightGBM\n",
    "\n",
    "With your data in place, you can now define the machine learning models. You'll apply Random Forrest and LightGBM models in this notebook. Use `scikit-learn` and `lightgbm` to implement the models within a few lines of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbdd7fd-a273-458c-9cea-dbcd583911dc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import the required libraries for model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix, recall_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72af93c-971d-4b13-9079-0025a5d78b32",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Prepare training, validation and test datasets\n",
    "\n",
    "Use the `train_test_split` function from `scikit-learn` to split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c539eed-0f88-4f0a-b7d2-901c2f9930e3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "y = df_clean[\"Exited\"]\n",
    "X = df_clean.drop(\"Exited\",axis=1)\n",
    "# Split the dataset to 60%, 20%, 20% for training, validation, and test datasets\n",
    "# Train-Test Separation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\n",
    "# Train-Validation Separation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228fa5a",
   "metadata": {},
   "source": [
    "### Save test data to a delta table\n",
    "\n",
    "Save the test data to the delta table for use in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ada79",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"df_test\"\n",
    "# Create PySpark DataFrame from Pandas\n",
    "df_test=spark.createDataFrame(X_test)\n",
    "df_test.write.mode(\"overwrite\").format(\"delta\").save(f\"Tables/{table_name}\")\n",
    "print(f\"Spark test DataFrame saved to delta table: {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c907a17c-ed92-4334-accc-2deec809334c",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "\n",
    "### Apply SMOTE to the training data to synthesize new samples for the minority class\n",
    "\n",
    "The data exploration in part 2 showed that out of the 10,000 data points corresponding to 10,000 customers, only 2,037 customers (around 20%) have left the bank. This indicates that the dataset is highly imbalanced. The problem with imbalanced classification is that there are too few examples of the minority class for a model to effectively learn the decision boundary. SMOTE is the most widely used approach to synthesize new samples for the minority class. Learn more about SMOTE [here](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html#) and [here](https://imbalanced-learn.org/stable/over_sampling.html#smote-adasyn).\n",
    "\n",
    "> [!TIP]\n",
    ">\n",
    "> Note that SMOTE should only be applied to the training dataset. You must leave the test dataset in its original imbalanced distribution in order to get a valid approximation of how the machine learning model will perform on the original data, which is representing the situation in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb6dec-3e17-498a-8e8d-380bc9a59f5a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=SEED)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "new_train = pd.concat([X_res, y_res], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1727fe26",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ac340-db04-4a2a-a504-a2a0295d0525",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "* Train the model using Random Forest with maximum depth of 4 and 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb7902-c40f-45a3-a7a1-6ab036bc19bc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(registered_model_name='rfc1_sm') # Register the trained model with autologging\n",
    "rfc1_sm = RandomForestClassifier(max_depth=4, max_features=4, min_samples_split=3, random_state=1) # Pass hyperparameters\n",
    "with mlflow.start_run(run_name=\"rfc1_sm\") as run:\n",
    "    rfc1_sm_run_id = run.info.run_id # Capture run_id for model prediction later\n",
    "    print(\"run_id: {}; status: {}\".format(rfc1_sm_run_id, run.info.status))\n",
    "    # rfc1.fit(X_train,y_train) # Imbalanaced training data\n",
    "    rfc1_sm.fit(X_res, y_res.ravel()) # Balanced training data\n",
    "    rfc1_sm.score(X_val, y_val)\n",
    "    y_pred = rfc1_sm.predict(X_val)\n",
    "    cr_rfc1_sm = classification_report(y_val, y_pred)\n",
    "    cm_rfc1_sm = confusion_matrix(y_val, y_pred)\n",
    "    roc_auc_rfc1_sm = roc_auc_score(y_res, rfc1_sm.predict_proba(X_res)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562edcf7-8926-4757-ad5a-871a1f813772",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "* Train the model using Random Forest with maximum depth of 8 and 6 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ab69b4-7098-4bfb-a393-fcd62a2bc0b4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(registered_model_name='rfc2_sm') # Register the trained model with autologging\n",
    "rfc2_sm = RandomForestClassifier(max_depth=8, max_features=6, min_samples_split=3, random_state=1) # Pass hyperparameters\n",
    "with mlflow.start_run(run_name=\"rfc2_sm\") as run:\n",
    "    rfc2_sm_run_id = run.info.run_id # Capture run_id for model prediction later\n",
    "    print(\"run_id: {}; status: {}\".format(rfc2_sm_run_id, run.info.status))\n",
    "    # rfc2.fit(X_train,y_train) # Imbalanced training data\n",
    "    rfc2_sm.fit(X_res, y_res.ravel()) # Balanced training data\n",
    "    rfc2_sm.score(X_val, y_val)\n",
    "    y_pred = rfc2_sm.predict(X_val)\n",
    "    cr_rfc2_sm = classification_report(y_val, y_pred)\n",
    "    cm_rfc2_sm = confusion_matrix(y_val, y_pred)\n",
    "    roc_auc_rfc2_sm = roc_auc_score(y_res, rfc2_sm.predict_proba(X_res)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46086429-c184-46b8-872b-58632eae583e",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "* Train the model using LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d92a2-17ea-43b0-b17c-b3fac5b76af6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# lgbm_model\n",
    "mlflow.lightgbm.autolog(registered_model_name='lgbm_sm') # Register the trained model with autologging\n",
    "lgbm_sm_model = LGBMClassifier(learning_rate = 0.07, \n",
    "                        max_delta_step = 2, \n",
    "                        n_estimators = 100,\n",
    "                        max_depth = 10, \n",
    "                        eval_metric = \"logloss\", \n",
    "                        objective='binary', \n",
    "                        random_state=42)\n",
    "\n",
    "with mlflow.start_run(run_name=\"lgbm_sm\") as run:\n",
    "    lgbm1_sm_run_id = run.info.run_id # Capture run_id for model prediction later\n",
    "    # lgbm_sm_model.fit(X_train,y_train) # Imbalanced training data\n",
    "    lgbm_sm_model.fit(X_res, y_res.ravel()) # Balanced training data\n",
    "    y_pred = lgbm_sm_model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    cr_lgbm_sm = classification_report(y_val, y_pred)\n",
    "    cm_lgbm_sm = confusion_matrix(y_val, y_pred)\n",
    "    roc_auc_lgbm_sm = roc_auc_score(y_res, lgbm_sm_model.predict_proba(X_res)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f8d4d-04ac-43a8-a6e4-1c10ace0c376",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Experiments artifact for tracking model performance\n",
    "\n",
    "The experiment runs are automatically saved in the experiment artifact that can be found from the workspace. They're named based on the name used for setting the experiment. All of the trained models, their runs, performance metrics and model parameters are logged. \n",
    "\n",
    "To view your experiments:\n",
    "1. On the left panel, select your workspace.\n",
    "1. Find and select the experiment name, in this case _bank-churn-experiment_. If you don't see the experiment in your workspace, refresh your browser.\n",
    "\n",
    "<img src=\"https://sdkstorerta.blob.core.windows.net/churnblob/experiment_runs.png\"  width=\"400%\" height=\"100%\" title=\"Screenshot shows logged values for one of the models.\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba64097-3c2a-4107-8f9d-a6b9b32a5dfe",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Assess the performances of the trained models on the validation dataset\n",
    "\n",
    "Once done with machine learning model training, you can assess the performance of trained models in two ways.\n",
    "\n",
    "- Open the saved experiment from the workspace, load the machine learning models, and then assess the performance of the loaded models on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5dd987-2bc0-4ece-839d-d1a1fe66b6f1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "ms_comment_ranges": {},
    "ms_comments": [],
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Define run_uri to fetch the model\n",
    "# mlflow client: mlflow.model.url, list model\n",
    "load_model_rfc1_sm = mlflow.sklearn.load_model(f\"runs:/{rfc1_sm_run_id}/model\")\n",
    "load_model_rfc2_sm = mlflow.sklearn.load_model(f\"runs:/{rfc2_sm_run_id}/model\")\n",
    "load_model_lgbm1_sm = mlflow.lightgbm.load_model(f\"runs:/{lgbm1_sm_run_id}/model\")\n",
    "# Assess the performance of the loaded model on validation dataset\n",
    "ypred_rfc1_sm_v1 = load_model_rfc1_sm.predict(X_val) # Random Forest with max depth of 4 and 4 features\n",
    "ypred_rfc2_sm_v1 = load_model_rfc2_sm.predict(X_val) # Random Forest with max depth of 8 and 6 features\n",
    "ypred_lgbm1_sm_v1 = load_model_lgbm1_sm.predict(X_val) # LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e95381-5bd2-443c-a65c-cbde66f2cd4a",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "- Directly assess the performance of the trained machine learning models on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b957a20e-abae-4dd1-a4a2-2bae28151c89",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ypred_rfc1_sm_v2 = rfc1_sm.predict(X_val) # Random Forest with max depth of 4 and 4 features\n",
    "ypred_rfc2_sm_v2 = rfc2_sm.predict(X_val) # Random Forest with max depth of 8 and 6 features\n",
    "ypred_lgbm1_sm_v2 = lgbm_sm_model.predict(X_val) # LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc22818b-6513-497d-9753-04dd6b1bcea2",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Depending on user's preference, either approach is fine and should offer identical performances. In this notebook, you'll choose the first approach in order to better demonstrate the MLflow autologging capabilities in Microsoft Fabric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eb022f-cf7a-4b1e-8c5c-d0c5dfe4a9f1",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    " #### Show True/False Positives/Negatives using the Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c96ca-677d-4204-8d7f-95eb7549d579",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Next, you'll develop a script to plot the confusion matrix in order to evaluate the accuracy of the classification using the validation dataset. The confusion matrix can be plotted using SynapseML tools as well, which is shown in Fraud Detection sample that is available [here](https://aka.ms/samples/frauddectection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae34cf-eed2-457f-8088-00f73acedd3b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"tab10\", rc = {'figure.figsize':(9,6)})\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib import rc, rcParams\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, color=\"blue\")\n",
    "    plt.yticks(tick_marks, classes, color=\"blue\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"red\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b394b5b7-f4ca-4838-b77f-8ef8bdfd409f",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "* Confusion Matrix for Random Forest Classifier with maximum depth of 4 and 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c19e11-fcab-4cd4-96d1-1f97a1ac7215",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "cfm = confusion_matrix(y_val, y_pred=ypred_rfc1_sm_v1)\n",
    "plot_confusion_matrix(cfm, classes=['Non Churn','Churn'],\n",
    "                      title='Random Forest with max depth of 4')\n",
    "tn, fp, fn, tp = cfm.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a20d7f-d9cb-42ca-a537-1b50894bedfb",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "* Confusion Matrix for Random Forest Classifier with maximum depth of 8 and 6 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fefc40-de64-4480-8f21-0efd11538f93",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "ms_comment_ranges": {},
    "ms_comments": [],
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "cfm = confusion_matrix(y_val, y_pred=ypred_rfc2_sm_v1)\n",
    "plot_confusion_matrix(cfm, classes=['Non Churn','Churn'],\n",
    "                      title='Random Forest with max depth of 8')\n",
    "tn, fp, fn, tp = cfm.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef73db99-3670-44cb-8e15-f3885ca9a02b",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "* Confusion Matrix for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05052942-cb51-461e-861c-8312bc6182d8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "cfm = confusion_matrix(y_val, y_pred=ypred_lgbm1_sm_v1)\n",
    "plot_confusion_matrix(cfm, classes=['Non Churn','Churn'],\n",
    "                      title='LightGBM')\n",
    "tn, fp, fn, tp = cfm.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e431d",
   "metadata": {},
   "source": [
    "## Next step\n",
    "\n",
    "Continue on to [Part 4: Perform batch scoring and save predictions to a lakehouse](https://learn.microsoft.com/fabric/data-science/tutorial-data-science-batch-scoring)."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "notebook_environment": {},
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "save_output": true,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {},
    "enableDebugMode": false
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
