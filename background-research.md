Perfect. I'll pull from the DP-600 cert for relevant skills and demos, and tailor this for data engineers, scientists, devs, and enterprise-focused practitioners using Microsoft's canonical fictional companies. I'll also surface common real-world use cases from Microsoft Fabric documentation and related enterprise patterns to build a high-impact, role-specific, demo-heavy Table of Contents.

Give me a moment to build that full storyline and course outline for you.

# Enterprise Analytics with Microsoft Fabric: End-to-End Hands-On Training (5-Part Course)

## Course Overview

**Audience:** Beginner-to-intermediate data engineers, data scientists, AI specialists, software developers, and professionals preparing for Microsoft Fabric certification (DP-600). This live training, led by a Microsoft MVP and MCT, emphasizes practical skills in Microsoft Fabric – an end-to-end analytics SaaS platform that unifies data integration, lakehouse storage, real-time processing, data science, and business intelligence ([What is Microsoft Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/fundamentals/microsoft-fabric-overview#:~:text=Microsoft%20Fabric%20is%20an%20enterprise,Intelligence%2C%20Data%20Warehouse%2C%20and%20Databases)). The course is structured into five 50-minute segments (with 9-minute breaks between) focused on live demonstrations (90% demo, 10% slides) using Windows 11, Microsoft 365, Azure services, Microsoft Fabric, and VS Code.

**Storyline:** Throughout the course, we follow a realistic scenario at Contoso (a fictional enterprise) as it modernizes its analytics platform with Microsoft Fabric. Contoso faces typical enterprise challenges – siloed data across systems, slow ETL processes, a need for real-time insights, and growing demand for AI/ML solutions. By adopting Fabric's unified analytics ecosystem, Contoso's data team will ingest and refine data in a **lakehouse**, incorporate streaming IoT and transactional data for real-time analytics, perform data science experiments, and deliver interactive dashboards – all within a governed, single environment. Attendees will see firsthand how Fabric's one-copy data lake (OneLake) eliminates duplication and silos ([Implement medallion lakehouse architecture in Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/onelake/onelake-medallion-lakehouse-architecture#:~:text=,than%20copying%20it%20to%20OneLake)), enabling multiple analytics engines to operate on the same data. Hands-on demos will show how to sign up for the **free Microsoft Fabric trial** ([Lakehouse end-to-end scenario: overview and architecture - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-engineering/tutorial-lakehouse-introduction#:~:text=1,can%20start%20the%20Fabric%20trial)) and use Fabric's integrated services to build an end-to-end solution, giving learners experience with high-priority use cases like data ingestion pipelines, lakehouse architecture (medallion design), real-time analytics for IoT, and collaborative data science workflows.

**Learning Objectives:** By the end of this course, attendees will be able to:

- Understand Microsoft Fabric's architecture and key components (OneLake, Lakehouse, Data Engineering, Data Factory, Real-Time Analytics, Data Science, Data Warehouse, Power BI) and how they work together in an enterprise scenario ([What is Microsoft Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/fundamentals/microsoft-fabric-overview#:~:text=Microsoft%20Fabric%20is%20an%20enterprise,Intelligence%2C%20Data%20Warehouse%2C%20and%20Databases)).

- Set up a Fabric workspace and lakehouse, and ingest data from various sources using pipelines with a medallion (bronze/silver/gold) architecture ([Implement medallion lakehouse architecture in Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/onelake/onelake-medallion-lakehouse-architecture#:~:text=Importantly%2C%20medallion%20architecture%20guarantees%20the,enriched)) to incrementally improve data quality.

- Build real-time event streams to capture and analyze streaming data (e.g. IoT sensor feeds, transactional logs) with no-code transformations, and route them to analytical stores for instant insights ([Microsoft Fabric event streams overview - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/real-time-intelligence/event-streams/overview#:~:text=The%20eventstreams%20feature%20in%20the,events%20using%20the%20Kafka%20protocol)).

- Use Fabric notebooks and Spark to perform data exploration and machine learning, training a model and tracking experiments within the Fabric environment ([Get started with data science in Microsoft Fabric - Training | Microsoft Learn](https://learn.microsoft.com/en-us/training/modules/get-started-data-science-fabric/#:~:text=In%20Microsoft%20Fabric%2C%20data%20scientists,with%20their%20fellow%20data%20professionals)) ([Get started with data science in Microsoft Fabric - Training | Microsoft Learn](https://learn.microsoft.com/en-us/training/modules/get-started-data-science-fabric/#:~:text=,metrics%20with%20MLflow%20and%20experiments)).

- Create enterprise-grade Power BI reports directly on the lakehouse data (using Direct Lake), and manage content lifecycle with deployment pipelines and built-in governance (Purview) for security ([What is Microsoft Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/fundamentals/microsoft-fabric-overview#:~:text=Fabric%20centralizes%20data%20discovery%2C%20administration%2C,without%20managing%20the%20underlying%20infrastructure)).

The course is highly practical – students can follow along using Fabric's free trial and Azure free services (for example, an Azure IoT or Event Hub for streaming data) if they wish. Each segment's live demo will showcase a slice of Contoso's analytics project, reinforcing how these tools and techniques apply to real-world enterprise needs. The narrative and demos use Microsoft's fictitious companies (Contoso, etc.) for realism, and the skills map to those measured in the DP-600 exam (Fabric Analytics Engineer Associate), although the focus is hands-on proficiency over exam preparation.

## Table of Contents

1. **Segment 1: Introduction to Microsoft Fabric and Contoso's Analytics Challenge**

2. **Segment 2: Building a Lakehouse – Data Ingestion and Preparation (Bronze/Silver Layers)**

3. **Segment 3: Real-Time Analytics – Streaming Data for Instant Insights**

4. **Segment 4: Advanced Analytics and AI – Data Science in Microsoft Fabric**

5. **Segment 5: Delivering Insights – Power BI, Deployment, and Governance in Fabric**

---

## Segment 1: Introduction to Microsoft Fabric and Contoso's Analytics Challenge

- **Microsoft Learn Module(s):** *What is Microsoft Fabric?* ([What is Microsoft Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/fundamentals/microsoft-fabric-overview#:~:text=Microsoft%20Fabric%20is%20an%20enterprise,Intelligence%2C%20Data%20Warehouse%2C%20and%20Databases)), *Lakehouse end-to-end scenario: overview and architecture* (Microsoft Learn tutorial) ([Lakehouse end-to-end scenario: overview and architecture - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-engineering/tutorial-lakehouse-introduction#:~:text=,first%20experience)).

- **Key Use Case(s):** Enterprise data unification and modernization. Contoso's leadership needs a single platform to consolidate data from sales, operations, and IoT systems, breaking down data silos and enabling faster insights. The use case is an end-to-end analytics overhaul – migrating from fragmented tools to Fabric's unified SaaS platform to support batch and real-time analytics, BI reporting, and AI, all under centralized governance.

- **Tools/Services Covered:** Microsoft Fabric **Workspace** (the container for all Fabric content), **OneLake** (the unified data lake storage – "one copy" of data across the organization ([Implement medallion lakehouse architecture in Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/onelake/onelake-medallion-lakehouse-architecture#:~:text=,than%20copying%20it%20to%20OneLake))), Fabric **UI in Power BI Service** (showing the various workloads: Data Engineering, Data Factory, Data Science, Real-Time Analytics, Data Warehouse, Power BI), and **Microsoft 365/Azure setup** (Power BI tenant and Azure subscription for connectivity). Also, overview of **VS Code** integration (how developers can use familiar IDE tools alongside Fabric, e.g. editing notebooks or using Git integration).

- **Live Demo Summary:** The instructor will kick off by logging into the Power BI portal on Windows 11 and activating the **Microsoft Fabric trial** ([Lakehouse end-to-end scenario: overview and architecture - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-engineering/tutorial-lakehouse-introduction#:~:text=1,can%20start%20the%20Fabric%20trial)) (for those without a Fabric license, demonstrating how to obtain a free Fabric license and trial). We'll tour the Fabric home interface, pointing out the tenant settings and the **Fabric capacities** (ensuring Fabric is enabled). Next, we'll create a new **Fabric workspace** for Contoso's project and show how OneLake is automatically available. The demo will highlight Fabric's linked experiences: we'll briefly click through the Data Engineering, Data Factory, Real-Time, and Power BI sections to explain their purpose. A simple example will be shown by uploading a small sample dataset (e.g. a CSV file of product data) into OneLake to illustrate the "single copy" principle – once in OneLake, the data can be accessed via different engines (SQL, Spark, etc.) without duplication ([Lakehouse end-to-end scenario: overview and architecture - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-engineering/tutorial-lakehouse-introduction#:~:text=,first%20experience)). The instructor will use a couple of slides (10% of segment) to explain Fabric's **architecture and value proposition** – how it **unifies data movement, storage, and analytics** in one platform ([What is Microsoft Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/fundamentals/microsoft-fabric-overview#:~:text=Microsoft%20Fabric%20is%20an%20enterprise,Intelligence%2C%20Data%20Warehouse%2C%20and%20Databases)). This sets the stage for the hands-on project.

- **Contoso Scenario Tie-In:** We meet the Contoso scenario: "Contoso Retail & Supply Co." has data scattered in CRM databases, Excel files, an on-prem data warehouse, and streaming sensors from delivery trucks. They struggle with slow, siloed analytics. In this segment, Contoso's data team (fictional characters introduced as our protagonists) present the plan to implement Microsoft Fabric as a unified analytics solution. They create a dedicated Fabric workspace for the project, representing a collaborative environment for data engineers, data scientists, and analysts. Contoso's CTO has approved a proof-of-concept using Fabric's trial environment, so the team starts there. This storyline establishes *why* Fabric is being used: to **eliminate data silos and provide a single source of truth** for Contoso's enterprise data ([Implement medallion lakehouse architecture in Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/onelake/onelake-medallion-lakehouse-architecture#:~:text=,than%20copying%20it%20to%20OneLake)). The segment concludes with Contoso's team ready to ingest data into their new Fabric lakehouse in Segment 2.

---

## Segment 2: Building a Lakehouse – Data Ingestion and Preparation (Bronze/Silver Layers)

- **Microsoft Learn Module(s):** *Lakehouse end-to-end scenario: Ingest data into the lakehouse* ([Lakehouse end-to-end scenario: overview and architecture - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-engineering/tutorial-lakehouse-introduction#:~:text=,to%20copy%20or%20move%20it)), *Lakehouse tutorial: Prepare and transform data in the lakehouse* ([Lakehouse end-to-end scenario: overview and architecture - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-engineering/tutorial-lakehouse-introduction#:~:text=,first%20experience)), *Implement medallion lakehouse architecture in Fabric* ([Implement medallion lakehouse architecture in Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/onelake/onelake-medallion-lakehouse-architecture#:~:text=Importantly%2C%20medallion%20architecture%20guarantees%20the,enriched)).

- **Key Use Case(s):** Batch data ingestion and lakehouse creation following the **medallion architecture** (Bronze, Silver, Gold) for a **Lakehouse**. Contoso needs to consolidate operational data (sales transactions, product info, customer data, etc.) into a central lakehouse. The use case highlights building a **single source of truth** through staged data refinement: ingest raw data (Bronze), cleanse and integrate it (Silver), and later (in a subsequent segment) prepare it for business consumption (Gold). This is a common enterprise scenario for **lakehouse architecture** – incrementally improving data quality and structure ([Implement medallion lakehouse architecture in Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/onelake/onelake-medallion-lakehouse-architecture#:~:text=Importantly%2C%20medallion%20architecture%20guarantees%20the,enriched)) to support analytics and BI.

- **Tools/Services Covered:** **Fabric Data Factory (Pipelines)** for orchestrating data movement, using the Copy Data activity and various connectors (e.g. to Azure Blob Storage, SQL databases, or REST endpoints – Fabric provides over *200 native connectors* for on-premises and cloud sources ([Lakehouse end-to-end scenario: overview and architecture - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-engineering/tutorial-lakehouse-introduction#:~:text=,to%20copy%20or%20move%20it))). **Fabric Lakehouse** in the Data Engineering experience – which provides a storage layer on OneLake with a **Files** section (for raw files) and a **Tables** section (for Delta tables). **Apache Spark notebooks** in Fabric (part of Data Engineering) for data transformation using PySpark or Spark SQL. We'll also see **Power Query/Dataflow Gen2** briefly as a no-code data prep alternative, though the focus will be on the code-first approach.

- **Live Demo Summary:** In this hands-on demo, Contoso's data engineer (the instructor in character) will ingest sample data into the Fabric lakehouse and perform transformations. First, using **Data Factory pipeline**, we create a new **pipeline** in Fabric and use a Copy Data activity to load raw data into the lakehouse's Bronze layer. For example, we'll connect to a public Contoso sales data source (simulated via an Azure Storage blob or a web URL) and copy a CSV or JSON dataset into the **Lakehouse Files (Bronze)** area. This demonstrates connecting to a source and landing data in OneLake. Next, we switch to the **Data Engineering** experience to transform the data. The instructor will open a **Spark notebook** attached to the lakehouse and read the raw data from the Files (Bronze) section. Using PySpark, they will cleanse and transform the data (e.g., remove duplicates, standardize formats, join with a lookup table) and then write out the results as a **Delta table** in the Lakehouse (this becomes our Silver layer table). The demo follows Fabric's recommended medallion pattern: the raw data is kept unchanged in Bronze, and after transformation, a Silver table contains the cleaned, structured data ([Implement medallion lakehouse architecture in Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/onelake/onelake-medallion-lakehouse-architecture#:~:text=Importantly%2C%20medallion%20architecture%20guarantees%20the,enriched)). We'll emphasize how Fabric's engines all use the Delta format on OneLake, so that once the Spark job creates the Delta table, it's immediately queryable via SQL or accessible to Power BI without further copies ([Lakehouse end-to-end scenario: overview and architecture - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-engineering/tutorial-lakehouse-introduction#:~:text=,first%20experience)). To visualize the process, the instructor shows a diagram of the medallion architecture in Fabric, explaining Bronze, Silver, Gold layers and how data flows through pipelines and notebooks into OneLake, then is ready for analysis via SQL endpoints or Power BI ([Implement medallion lakehouse architecture in Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/onelake/onelake-medallion-lakehouse-architecture#:~:text=,like%20customer%2C%20product%2C%20and%20others)) ([Implement medallion lakehouse architecture in Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/onelake/onelake-medallion-lakehouse-architecture#:~:text=,conform%20to%20star%20schema%20design)). ([Implement medallion lakehouse architecture in Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/onelake/onelake-medallion-lakehouse-architecture)) *Illustration: Medallion architecture in Fabric – data from various sources lands in a Bronze (raw) OneLake zone via pipelines/shortcuts, gets refined in Silver and Gold layers via notebooks or dataflows, and is then analyzed through the lakehouse's SQL endpoint or Power BI (Direct Lake)*. After the Spark notebook run, the Contoso team now has, for example, a **SalesSilver** Delta table with clean sales data. We conclude the demo by previewing that table using both Spark (in the notebook) and a quick SQL query via the lakehouse's built-in SQL interface, showing the data is accessible in multiple ways without duplication.

- **Contoso Scenario Tie-In:** In the story, Contoso's data engineering team sets up the **Contoso Lakehouse** to serve as the enterprise data hub. They ingest raw export files from Contoso's legacy sales database and ERP system into the **Bronze** layer of the lakehouse. This raw data includes all the inconsistencies and errors from source. The team then applies cleaning rules and combines the data with reference information (e.g., product categories from a master data Excel) in the **Silver** layer. For example, they standardize country names, remove invalid records, and integrate sales with product info. By the end of this segment, Contoso has a **validated Silver dataset** of sales ready for analysis. The narrative highlights the benefit: even at this stage, any analyst at Contoso could connect to the Silver table for ad-hoc queries, and since it's in OneLake as Delta, multiple tools can use it concurrently (the team mentions that **OneLake's single copy** approach avoids making siloed copies for each department). Contoso's CIO is pleased to see that data ingestion which previously took days of manual ETL is now automated with Fabric pipelines. This sets the stage for the next steps – adding real-time data to the mix and further refining data for advanced analytics.

---

## Segment 3: Real-Time Analytics – Streaming Data for Instant Insights

- **Microsoft Learn Module(s):** *Use real-time eventstreams in Microsoft Fabric* ([Microsoft Fabric event streams overview - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/real-time-intelligence/event-streams/overview#:~:text=The%20eventstreams%20feature%20in%20the,events%20using%20the%20Kafka%20protocol)), *Implement Real-Time Intelligence with Microsoft Fabric* (Learn module covering event stream and KQL database).

- **Key Use Case(s):** Real-time data ingestion and analysis for immediate business value. Contoso wants to perform **real-time analytics** on streaming data – a high-priority use case for scenarios like **IoT monitoring and fraud detection**. For example, Contoso's supply chain division needs to monitor telemetry from delivery trucks (temperature, location, etc.) live to ensure product quality, and the finance team wants to detect suspicious transactions as they happen. In general, **fast access to event data is essential for timely action** in many enterprises; preventing disruptions in a supply chain can require real-time monitoring of inventory and delivery status, and manufacturing units benefit from instant insight into sensor readings (temperature, pressure) to optimize operations ([Microsoft Fabric Enables Realtime Analytics for Business Success | element61](https://www.element61.be/en/resource/microsoft-fabric-enables-realtime-analytics-business-success#:~:text=Fast%20access%20to%20event%20data,chemical%20sampling%20of%20wastewater%20effluent)). This segment addresses those use cases by leveraging Fabric's real-time analytics capabilities.

- **Tools/Services Covered:** **Fabric Real-Time Analytics** – primarily the **Eventstream** feature and the **KQL databases** (built on Azure Data Explorer technology) for ad-hoc querying of streamed data. The Eventstream is a no-code streaming data pipeline within Fabric that can connect to sources such as IoT Hub, Event Hubs, or database change feeds, perform optional transformations, and route events to multiple destinations (like a KQL database, a Lakehouse, or a Data Warehouse) ([Microsoft Fabric event streams overview - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/real-time-intelligence/event-streams/overview#:~:text=The%20eventstreams%20feature%20in%20the,events%20using%20the%20Kafka%20protocol)). We will also see **Azure IoT Hub or Event Hub** (as the source of streaming data in our demo scenario), showing how Fabric integrates with Azure services. Tools include the Eventstream editor (visual interface to map sources to destinations and apply transformations) and the Real-Time monitoring tools in Fabric (to watch incoming events). Additionally, we'll use **Kusto Query Language (KQL)** to query the streamed data in real-time.

- **Live Demo Summary:** The demo begins with setting up a streaming data source. The instructor will simulate a stream of data – for instance, generate synthetic IoT sensor readings (e.g., temperature and location data from Contoso's delivery trucks) or use a sample **Azure IoT Hub** feed. Using the Fabric portal, we'll create a new **Eventstream** in the Real-Time Analytics experience. In the Eventstream configuration, we add a **source** (for example, an Azure IoT Hub connection or a sample generator) to ingest events. We then configure a simple **transformation** within the event stream (demonstrating the no-code editor – for instance, filtering out sensor readings that are within normal range, or enriching events with a timestamp). Next, we set up two **destinations** for the stream: (1) a **KQL database** (Eventstream can automatically land events into a Kusto engine for analytics), and (2) the **Lakehouse** (to land the raw events into a Bronze table for historical storage). The Eventstream is started, and we can watch in real-time as data flows. The instructor will show the **Real-Time Monitoring** view to confirm events are being ingested. Once data is streaming, we pivot to consuming it: using the built-in **KQL query** interface (or a Fabric notebook with Kusto), we run some ad-hoc queries on the live data (e.g., average truck temperature in the last 5 minutes, or detecting any out-of-threshold readings). This demonstrates how Fabric enables **analysis of streaming events in near real-time**. We might also quickly create a simple Power BI dashboard or Fabric **Real-Time dashboard** to visualize the streaming data (for example, a live chart of sensor readings) – showing business users can see updates instantly. The live demo underlines that Eventstreams let us capture and route events to multiple targets without writing code ([Microsoft Fabric event streams overview - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/real-time-intelligence/event-streams/overview#:~:text=The%20eventstreams%20feature%20in%20the,events%20using%20the%20Kafka%20protocol)), and how this fits a **Lambda architecture** style (speed layer for real-time alongside batch layer).

- **Contoso Scenario Tie-In:** In Contoso's story, the team extends their Fabric solution to include streaming data. They configure an event stream for the **IoT sensors in Contoso's delivery trucks**. As trucks carry perishable goods, temperature and location data need to be monitored in real time to prevent spoilage. Using Fabric, Contoso can now see these readings live: if a truck's cooler fails and temperature rises above a threshold, the system can alert logistics managers immediately (this is noted as a future step where **Fabric's Data Activator** could trigger an alert, hinting at proactive actions). Additionally, Contoso's e-commerce wing starts streaming website clickstream and transaction events through the same pipeline to detect potential fraud – for instance, unusually large orders or rapid sequence of transactions can be flagged in seconds for review. The narrative shows Contoso achieving a **real-time intelligence** capability that was previously absent. By integrating the Eventstream with their lakehouse, they also ensure that all streaming data is saved for later analysis (for example, joining sensor data with sales data to analyze delivery impact on product quality). At the end of this segment, Contoso's analytics platform now covers both batch data (from Segment 2) and streaming data (Segment 3), giving them a **complete data picture**. Stakeholders at Contoso, like the operations manager and CFO, are impressed to see live dashboards and timely alerts, illustrating Fabric's value in enterprise scenarios where every second counts.

---

## Segment 4: Advanced Analytics and AI – Data Science in Microsoft Fabric

- **Microsoft Learn Module(s):** *Get started with data science in Microsoft Fabric* ([Get started with data science in Microsoft Fabric - Training | Microsoft Learn](https://learn.microsoft.com/en-us/training/modules/get-started-data-science-fabric/#:~:text=In%20Microsoft%20Fabric%2C%20data%20scientists,with%20their%20fellow%20data%20professionals)), *Explore data for data science with notebooks in Microsoft Fabric* ([Explore data for data science with notebooks in Microsoft Fabric - Training | Microsoft Learn](https://learn.microsoft.com/en-us/training/modules/explore-data-for-data-science-microsoft-fabric/#:~:text=Microsoft%20Fabric%20notebooks%20serve%20as,and%20relationships%20in%20their%20datasets)).

- **Key Use Case(s):** Data science and machine learning on enterprise data. With Contoso's data now unified and flowing, the next high-value use case is deriving **predictive insights** – for example, sales forecasting, customer segmentation, or anomaly detection. Common scenarios include training ML models on historical data to predict future outcomes (demand forecasting, predictive maintenance) or to classify data (e.g., identifying high-risk transactions or segmenting customers by behavior). This segment focuses on the **data science workflow** in Fabric: exploratory data analysis (EDA), feature engineering, model training, and experiment tracking, all within the Fabric environment. It addresses the needs of data scientists and AI specialists who want to work directly where the data lives, collaborate with engineers, and easily deploy models.

- **Tools/Services Covered:** **Fabric Notebooks** (Jupyter-compatible notebooks integrated in Fabric) using **Apache Spark** as the compute engine for scalable data processing and ML (or optionally **Python libraries** on smaller data via the built-in compute). Fabric's Data Science experience provides an environment to manage **experiments and models** – including **MLflow** for tracking metrics and model parameters. We will see how notebooks can be attached to the lakehouse (so they directly read data from OneLake) and how to use popular Python libraries (pandas, PySpark, scikit-learn or MLlib) in Fabric. We'll also mention **Fabric MLflow integration** (for tracking runs) and the concept of registering models in Fabric (or integrating with Azure Machine Learning if needed). Additionally, we may use **VS Code** to demonstrate that notebooks can be edited or executed from an IDE, highlighting a developer-friendly workflow.

- **Live Demo Summary:** The instructor now takes the role of Contoso's data scientist. Building on the Silver layer data prepared earlier (Segment 2) and incorporating fresh data (including possibly some features from the streaming IoT data), we perform an end-to-end data science process. The demo starts with a **notebook** in Fabric where we do **Exploratory Data Analysis (EDA)** on the Contoso sales dataset. We'll use Python (pandas or PySpark DataFrame) to compute statistics, visualize distributions of sales over time, and maybe plot trends (leveraging built-in plotting libraries). This demonstrates how Fabric notebooks enable users to **uncover hidden patterns and relationships in their datasets ([Explore data for data science with notebooks in Microsoft Fabric - Training | Microsoft Learn](https://learn.microsoft.com/en-us/training/modules/explore-data-for-data-science-microsoft-fabric/#:~:text=Microsoft%20Fabric%20notebooks%20serve%20as,and%20relationships%20in%20their%20datasets))**. Next, we prepare the data for modeling: for instance, creating features such as month-over-month sales growth or combining sales with promotional events data. With the feature set ready, we proceed to **train a machine learning model**. For example, we could train a regression model to forecast next month's sales for each product or a classification model to predict whether a customer will churn. Using **scikit-learn** (running on Fabric's Spark compute or local CPU), we train the model within the notebook. We utilize Fabric's integration with **MLflow** to log the experiment – the model's parameters and performance metrics (like RMSE for regression or accuracy for classification) are automatically tracked ([Get started with data science in Microsoft Fabric - Training | Microsoft Learn](https://learn.microsoft.com/en-us/training/modules/get-started-data-science-fabric/#:~:text=,metrics%20with%20MLflow%20and%20experiments)). The instructor shows the Fabric **experiments** UI where the run appears with metrics, illustrating built-in experiment tracking. We might run a couple of variations (tuning a hyperparameter) to show how MLflow records each run. After training, we demonstrate saving the model artifact to the workspace (or registering it, if supported, for future usage). Finally, we simulate using the model: e.g., use the model to predict outcomes on a new sample of data and show the results in the notebook. Throughout the demo, we emphasize the collaborative aspect – data engineers and data scientists are working in the same Fabric environment, so the notebooks have easy access to the lakehouse data without needing separate infrastructure. Fabric provides a one-stop-shop where **data scientists can manage data, notebooks, experiments, and models while accessing data across the organization and collaborating with their peers ([Get started with data science in Microsoft Fabric - Training | Microsoft Learn](https://learn.microsoft.com/en-us/training/modules/get-started-data-science-fabric/#:~:text=In%20Microsoft%20Fabric%2C%20data%20scientists,with%20their%20fellow%20data%20professionals))**. This segment is mostly live coding in the notebook, highlighting a practical machine learning task on enterprise data.

- **Contoso Scenario Tie-In:** In the Contoso narrative, this stage represents the company's move from descriptive analytics to **predictive analytics**. Contoso's data science team, now empowered with a cleansed dataset and real-time inputs, builds a machine learning model to solve a key business problem. For instance, they develop a **sales demand forecasting model** to help Contoso optimize inventory. The story details how the data scientists load the past sales data (which the data engineering team prepared in the Silver layer) and combine it with external factors like seasonality or promotions. They explore the data (finding patterns such as holiday spikes and weekday vs weekend sales differences) and then create a forecasting model. The first iteration of the model is trained and evaluated – in our example, perhaps the model can predict next month's sales within a certain error margin. Contoso's team tracks the results of several experiments using Fabric's MLflow integration, improving the model incrementally. They are pleased to do this within Fabric because it **eliminates the friction of moving data to a separate ML environment** – the data stays in OneLake, and the compute came to the data. By the end of the segment, Contoso has a working predictive model. The stakeholders (like the head of sales or supply chain manager) are excited at the prospect of using this model to drive decisions (e.g., stocking products based on forecast). This demonstrates Fabric's support for advanced analytics: from raw data to ML insights in one platform. The segment sets up the finale, where Contoso will operationalize these insights and share them with the business through dashboards, while also addressing deployment and governance.

---

## Segment 5: Delivering Insights – Power BI, Deployment, and Governance in Fabric

- **Microsoft Learn Module(s):** *Create a Power BI report using DirectLake* ([Lakehouse end-to-end scenario: overview and architecture - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-engineering/tutorial-lakehouse-introduction#:~:text=SQL%20analytics%20endpoint%20mode.%20,sales%20data%20across%20different%20dimensions)) (from the lakehouse tutorial), *Overview of Fabric deployment pipelines* (Learn module on CI/CD in Fabric) ([Overview of Fabric deployment pipelines - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/cicd/deployment-pipelines/intro-to-deployment-pipelines#:~:text=Microsoft%20Fabric%27s%20deployment%20pipelines%20tool,types%20that%20you%20can%20deploy)), *Implement security and governance in Fabric* (Microsoft documentation on Purview integration) ([What is Microsoft Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/fundamentals/microsoft-fabric-overview#:~:text=Fabric%20centralizes%20data%20discovery%2C%20administration%2C,without%20managing%20the%20underlying%20infrastructure)).

- **Key Use Case(s):** Business intelligence delivery and platform management. This final segment focuses on taking the prepared data and models and **delivering insights to end users** in a governed, enterprise-friendly way. The primary use case is building interactive **Power BI reports** and dashboards on top of the Fabric lakehouse Gold layer, enabling decision-makers at Contoso to explore the data (e.g., sales by region, product performance, real-time metrics). Another use case is ensuring proper **DevOps and governance**: managing the content lifecycle (dev → test → prod deployments of reports and datasets), implementing security (row-level security on data, workspace permissions), and complying with governance (data sensitivity labels, data lineage tracking). In enterprise scenarios, it's crucial not only to develop analytics but also to operationalize and maintain them with proper controls.

- **Tools/Services Covered:** **Power BI in Fabric** – creating a **Power BI Dataset** (semantic model) connected to the lakehouse and building a report. We specifically use **Direct Lake mode**, a new connectivity that allows Power BI to query the Delta tables in OneLake with high performance (combining benefits of import and direct query) ([Lakehouse end-to-end scenario: overview and architecture - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-engineering/tutorial-lakehouse-introduction#:~:text=,and%20schedule%20data%20ingestion%20and)). We'll show Power BI report authoring (in the web or using Power BI Desktop connected to Fabric) to build visuals like sales trends, top products, etc. Additionally, **Fabric Deployment Pipelines** will be introduced as a tool to promote content from a development workspace to a production workspace in a controlled manner ([Overview of Fabric deployment pipelines - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/cicd/deployment-pipelines/intro-to-deployment-pipelines#:~:text=Microsoft%20Fabric%27s%20deployment%20pipelines%20tool,types%20that%20you%20can%20deploy)). We will also touch on **Security & Governance** features: managing **workspace access roles**, applying **Row-Level Security (RLS)** to the dataset (so, for example, regional managers see only their region's data), and using **Microsoft Purview** integration for data governance (Fabric automatically carries over sensitivity labels and access permissions across assets ([What is Microsoft Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/fundamentals/microsoft-fabric-overview#:~:text=Fabric%20centralizes%20data%20discovery%2C%20administration%2C,without%20managing%20the%20underlying%20infrastructure))). Tools like the Fabric **Admin Portal** and **Workspace settings** will be shown for how governance is enforced. If time permits, we will also mention **Version control (Git integration)** for artifacts and demonstrate how one could link a workspace to a Git repo for versioning of notebooks or pipelines.

- **Live Demo Summary:** In this final demo, we step into the shoes of a Contoso BI developer and administrator to **create a report and deploy the solution**. First, using Power BI (either the web authoring or Power BI Desktop connected to Fabric's dataset), we build a **Power BI semantic model** on the curated Gold data. The instructor will open the **Lakehouse SQL Endpoint** or use the **Direct Lake connection** to create a new Power BI dataset that includes key tables (e.g., Sales (Gold), Product dimensions, perhaps the output of the ML model like a forecast table). We define relationships (if needed) and possibly some DAX measures (e.g., Total Sales, Year-over-Year Growth). Then, we create a report with a few visuals: a sales dashboard showing revenue by month, by category, and a map of sales by region, as well as a card showing a forecast from our ML model for next month. Thanks to Direct Lake, once this dataset is set up, any changes in the underlying Delta table are reflected in visuals without needing a manual refresh (the instructor will note this advantage). After designing the report, we simulate **publishing** it (if using Desktop) or saving it in the workspace (if web). Now, we have a "Contoso Sales Analytics" report ready for business users. Next, we demonstrate deploying and securing it. Using **Fabric's deployment pipeline** feature, the instructor shows a pipeline that has Development, Test, and Production stages. We add our dataset and report to the pipeline and with one click **deploy to Test**, illustrating how Fabric promotes the content. In a real scenario, this is where QA would happen; then deploy to Production to release to users ([Overview of Fabric deployment pipelines - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/cicd/deployment-pipelines/intro-to-deployment-pipelines#:~:text=Microsoft%20Fabric%27s%20deployment%20pipelines%20tool,types%20that%20you%20can%20deploy)). We discuss that deployment pipelines help catch issues and manage configuration (e.g., parameter differences between dev and prod, such as connecting to a production database vs. a sample). Finally, we cover **governance**: in the Fabric workspace, we set view permissions such that only authorized Contoso managers can see the report. We also demonstrate applying a **Sensitivity label** (e.g., "Confidential") to the dataset, and show that Fabric's Purview integration carries this label and access rules wherever the data goes ([What is Microsoft Fabric - Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/fundamentals/microsoft-fabric-overview#:~:text=Fabric%20centralizes%20data%20discovery%2C%20administration%2C,without%20managing%20the%20underlying%20infrastructure)). If applicable, the instructor will show lineage view, illustrating how data flows from the lakehouse to the dataset to the report, which helps with impact analysis and governance. To wrap up the demo, we switch to the perspective of a Contoso end user (for example, a sales manager) opening the Power BI report in the Contoso Fabric app. They can interact with filters and see the latest numbers (even incorporating the real-time and forecast elements we added). This final demo delivers the "last mile" of analytics – from data to insights delivered in a user-friendly form – and shows the behind-the-scenes process to ensure it's done professionally and securely.

- **Contoso Scenario Tie-In:** The concluding chapter of Contoso's journey has the data team **deliver the solution to the business**. They create a rich Power BI dashboard titled "Contoso Sales & Operations Dashboard" that combines all their work: it pulls from the Gold layer of the lakehouse (which includes cleaned historical data), displays real-time metrics (like a live tile showing the number of active delivery trucks over temperature threshold right now), and integrates results from the machine learning model (forecasted next-month sales by product line). Executives at Contoso now have a single pane of glass for insights – they can slice and dice sales data, monitor operational health in real-time, and even see predictions, all in one report. The **enterprise relevance** is underscored by Contoso's CIO: they required that this solution adhere to compliance and quality standards. The data team used Fabric's governance features to satisfy IT auditors – for instance, applying sensitivity labels to ensure any exports of data are tracked, and implementing row-level security so each regional manager only sees their region's figures. They also set up a deployment pipeline, meaning future updates to the dataset or reports can be tested safely before affecting executives. In the story's conclusion, Contoso has successfully transformed their analytics infrastructure within a unified Microsoft Fabric environment. They have a true **end-to-end analytics platform**: data flows from source to insight in a seamless, automated way, and all the personas (data engineer, data scientist, BI developer, and business user) collaborated through Fabric. The company is now equipped to make faster, data-driven decisions. The course ends with this positive outcome, reinforcing how the learned skills and Fabric features come together in a real-world enterprise scenario to drive business value.

